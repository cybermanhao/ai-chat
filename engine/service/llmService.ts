// engine/service/llmService.ts
// å¤šç«¯åŒæ„ LLMService çº¯é€»è¾‘å®ç°
import { OpenAI } from 'openai';
import type {
  ChatCompletionCreateParams,
  ChatCompletionMessageParam
} from 'openai/resources/chat/completions';
import type { ChatMessage } from '../types/chat';
import type { ModelConfig } from '../types/model';
import type { Stream } from 'openai/streaming';
import type { ExtendedChatCompletionChunk } from '../types/openai-extended';
import type { LLMConfig } from '../types/llm';
import { handleResponseStream } from '../stream/streamHandler';

export let currentStream: AsyncIterable<any> | null = null;

// å·¥å…·é“¾/åå¤„ç† glue é¢„ç•™æ¥å£
export type PostProcessMessages = (messages: any[]) => Promise<void>;
export type OcrService = (imageData: any) => Promise<string>;
export type ImageService = (imageData: any) => Promise<any>;

export async function streamLLMChat({
  chatId,
  baseURL,
  apiKey,
  model,
  messages,
  temperature,
  tools = [],
  parallelToolCalls = true,
  proxyServer = '',
  onChunk,
  onDone,
  onError,
  onToolCall,
  // postProcessMessages,
  // ocrService, // é¢„ç•™ OCR glue
  // imageService, // é¢„ç•™å›¾ç‰‡ glue
  customFetch,
  signal,
  assistantMessageId, // æ–°å¢ï¼šä¼ å…¥å›ºå®šçš„ assistant æ¶ˆ Messages ID
}: {
  chatId?: string; // å¯é€‰ï¼Œä¾¿äºè·Ÿè¸ªä¼šè¯
  baseURL: string;
  apiKey: string;
  model: string;
  messages: any[];
  temperature?: number;
  tools?: any[];
  parallelToolCalls?: boolean;
  proxyServer?: string;
  onChunk?: (chunk: any) => void;
  onDone?: (result: any) => void;
  onError?: (err: any) => void;
  onToolCall?: (toolCall: any) => void;
  // postProcessMessages?: PostProcessMessages;
  // ocrService?: OcrService;
  // imageService?: ImageService;
  customFetch?: typeof fetch;
  signal?: AbortSignal;
  assistantMessageId?: string; // å›ºå®šçš„ assistant æ¶ˆæ¯ ID
}) {
  // æ¶ˆæ¯åå¤„ç†ï¼ˆå¦‚æœ‰ OCRã€å›¾ç‰‡ç­‰ glueï¼Œå¯åœ¨æ­¤è°ƒç”¨ï¼‰
  // if (postProcessMessages) {
  //   await postProcessMessages(messages);
  // }
  // å¦‚éœ€ OCR glueï¼Œå¯åœ¨æ­¤è°ƒç”¨ ocrService(imageData)
  // å¦‚éœ€å›¾ç‰‡ glueï¼Œå¯åœ¨æ­¤è°ƒç”¨ imageService(imageData)

  // Debug logs can be enabled for debugging (currently commented out for performance)
  console.log('[streamLLMChat] æ¥æ”¶åˆ°çš„å‚æ•°:');
  console.log('[streamLLMChat] baseURL:', baseURL);
  console.log('[streamLLMChat] model:', model);
  console.log('[streamLLMChat] apiKey:', apiKey ? '***å·²è®¾ç½®***' : 'æœªè®¾ç½®');
  console.log('[streamLLMChat] messages æ•°é‡:', messages.length);
  console.log('[streamLLMChat] tools æ•°é‡:', tools?.length || 0);
  console.log('[streamLLMChat] parallelToolCalls åŸå§‹å€¼:', parallelToolCalls);
  console.log('[streamLLMChat] temperature:', temperature);

  const client = new OpenAI({
    baseURL,
    apiKey,
    fetch: customFetch,
    dangerouslyAllowBrowser: true
  });

  const seriableTools = (tools && tools.length === 0) ? undefined : tools;
  const seriableParallelToolCalls = (tools && tools.length > 0) ? parallelToolCalls : undefined;

  console.log('[streamLLMChat] åºåˆ—åŒ–åçš„å‚æ•°:');
  console.log('[streamLLMChat] seriableTools:', seriableTools ? `${seriableTools.length} ä¸ªå·¥å…·` : 'undefined');
  console.log('[streamLLMChat] seriableParallelToolCalls:', seriableParallelToolCalls);

  // æ¸…ç†æ¶ˆæ¯æ ¼å¼ï¼Œç¡®ä¿åªåŒ…å« API éœ€è¦çš„å­—æ®µ
  const cleanMessages = messages
    .filter(msg => {
      // åŸºæœ¬éªŒè¯ï¼šå¿…é¡»æœ‰ role
      if (!msg || !msg.role) return false;
      
      // tool æ¶ˆæ¯å¿…é¡»æœ‰ tool_call_idï¼Œcontent å¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²
      if (msg.role === 'tool') {
        return !!(msg as any).tool_call_id;
      }
      
      // å…¶ä»–æ¶ˆæ¯å¿…é¡»æœ‰ content
      return msg.content !== undefined;
    })
    .map(msg => {
      const cleanMsg: any = {
        role: msg.role,
        content: msg.content || '', // ç¡®ä¿ content ä¸ä¸º undefined
      };

      // ä¿ç•™å…¶ä»–å¿…è¦çš„ OpenAI å­—æ®µ
      if (msg.name) cleanMsg.name = msg.name;

      // åªæœ‰å½“ tool_calls å­˜åœ¨ä¸”éç©ºæ—¶æ‰åŒ…å«
      if (msg.tool_calls && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) {
        cleanMsg.tool_calls = msg.tool_calls;
        // console.log('[llmService] åŒ…å« tool_calls:', msg.tool_calls.length, 'ä¸ª');
      } else if (msg.tool_calls) {
        // console.log('[llmService] è·³è¿‡ç©ºçš„ tool_calls æ•°ç»„, é•¿åº¦:', Array.isArray(msg.tool_calls) ? msg.tool_calls.length : 'éæ•°ç»„');
      }

      // ç‰¹åˆ«é‡è¦ï¼šä¿ç•™ tool_call_id ç”¨äºå·¥å…·å“åº”æ¶ˆæ¯
      if ((msg as any).tool_call_id) {
        cleanMsg.tool_call_id = (msg as any).tool_call_id;
      }

      return cleanMsg;
    });

  // Debug logs can be enabled for debugging (currently commented out for performance)
  console.log('[llmService] åŸå§‹ messages:', messages);
  console.log('[llmService] æ¸…ç†åçš„ messages:', cleanMessages);
  
  // ç‰¹åˆ«æ£€æŸ¥å·¥å…·è°ƒç”¨ç›¸å…³æ¶ˆæ¯
  const assistantWithTools = cleanMessages.filter(msg => msg.role === 'assistant' && msg.tool_calls);
  const toolMessages = cleanMessages.filter(msg => msg.role === 'tool');
  console.log('[llmService] åŠ©æ‰‹å·¥å…·è°ƒç”¨æ¶ˆæ¯:', assistantWithTools.length, 'ä¸ª');
  console.log('[llmService] å·¥å…·å“åº”æ¶ˆæ¯:', toolMessages.length, 'ä¸ª');
  
  if (assistantWithTools.length > 0) {
    console.log('[llmService] æœ€æ–°çš„åŠ©æ‰‹å·¥å…·è°ƒç”¨:', JSON.stringify(assistantWithTools[assistantWithTools.length - 1], null, 2));
  }
  
  if (toolMessages.length > 0) {
    console.log('[llmService] å·¥å…·å“åº”æ¶ˆæ¯è¯¦æƒ…:', JSON.stringify(toolMessages, null, 2));
  }
  
  // éªŒè¯å·¥å…·è°ƒç”¨å’Œå“åº”çš„é…å¯¹å…³ç³»
  if (assistantWithTools.length > 0) {
    const lastAssistantWithTools = assistantWithTools[assistantWithTools.length - 1];
    const expectedToolCallIds = lastAssistantWithTools.tool_calls?.map(tc => tc.id) || [];
    const actualToolCallIds = toolMessages.map(tm => tm.tool_call_id);
    
    console.log('[llmService] æœŸæœ›çš„ tool_call_ids:', expectedToolCallIds);
    console.log('[llmService] å®é™…çš„ tool_call_ids:', actualToolCallIds);
    
    const missingResponses = expectedToolCallIds.filter(id => !actualToolCallIds.includes(id));
    const extraResponses = actualToolCallIds.filter(id => !expectedToolCallIds.includes(id));
    
    if (missingResponses.length > 0) {
      console.warn('[llmService] ç¼ºå°‘å¯¹åº”çš„å·¥å…·å“åº”æ¶ˆæ¯:', missingResponses);
    }
    if (extraResponses.length > 0) {
      console.warn('[llmService] å¤šä½™çš„å·¥å…·å“åº”æ¶ˆæ¯:', extraResponses);
    }
  }
  
  // å¢å¼ºéªŒè¯ï¼šæ£€æŸ¥æ•´ä¸ªæ¶ˆæ¯åºåˆ—çš„å®Œæ•´æ€§
  let messageSequenceValid = true;
  let sequenceErrors: string[] = [];
  
  for (let i = 0; i < cleanMessages.length; i++) {
    const msg = cleanMessages[i];
    
    // å¦‚æœæ˜¯å¸¦ tool_calls çš„ assistant æ¶ˆæ¯
    if (msg.role === 'assistant' && msg.tool_calls && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) {
      const expectedIds = msg.tool_calls.map(tc => tc.id);
      const foundIds: string[] = [];
      
      // æ£€æŸ¥åç»­æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„ tool å“åº”
      for (let j = i + 1; j < cleanMessages.length; j++) {
        const nextMsg = cleanMessages[j];
        if (nextMsg.role === 'tool' && nextMsg.tool_call_id) {
          if (expectedIds.includes(nextMsg.tool_call_id)) {
            foundIds.push(nextMsg.tool_call_id);
          }
        }
        // å¦‚æœé‡åˆ°ä¸‹ä¸€ä¸ª assistant æ¶ˆæ¯ï¼Œåœæ­¢æœç´¢
        if (nextMsg.role === 'assistant') {
          break;
        }
      }
      
      const missingIds = expectedIds.filter(id => !foundIds.includes(id));
      if (missingIds.length > 0) {
        messageSequenceValid = false;
        sequenceErrors.push(`Assistant æ¶ˆæ¯ ${i} çš„å·¥å…·è°ƒç”¨ç¼ºå°‘å“åº”: ${missingIds.join(', ')}`);
      }
    }
  }
  
  if (!messageSequenceValid) {
    console.error('[llmService] æ¶ˆæ¯åºåˆ—éªŒè¯å¤±è´¥:', sequenceErrors);
    console.error('[llmService] å®Œæ•´æ¶ˆæ¯åºåˆ—:', cleanMessages.map((msg, idx) => ({
      index: idx,
      role: msg.role,
      has_content: !!msg.content,
      has_tool_calls: !!(msg.tool_calls && msg.tool_calls.length > 0),
      tool_call_id: msg.tool_call_id,
      tool_calls_ids: msg.tool_calls?.map(tc => tc.id)
    })));
  } else {
    console.log('[llmService] æ¶ˆæ¯åºåˆ—éªŒè¯é€šè¿‡ âœ“');
  }

  const requestParams: ChatCompletionCreateParams = {
    model,
    messages: cleanMessages,
    temperature,
    stream: true,
    ...(seriableTools && { tools: seriableTools }),
    ...(seriableParallelToolCalls !== undefined && { parallel_tool_calls: seriableParallelToolCalls }),
  };

  console.log('[streamLLMChat] æœ€ç»ˆè¯·æ±‚å‚æ•°:', JSON.stringify(requestParams, null, 2));

  const stream = await client.chat.completions.create(requestParams, { signal });

  // ä½¿ç”¨streamHandlerå¤„ç†å®Œæ•´é€»è¾‘ï¼Œç”±MessageBridgeè´Ÿè´£å¢é‡å¤„ç†
  try {
    // è®°å½•å·²è§¦å‘çš„å·¥å…·è°ƒç”¨ï¼Œé¿å…é‡å¤è§¦å‘
    const triggeredToolCalls = new Set<string>();
    
    const result = await handleResponseStream(stream, (chunk) => {
      // ç»§ç»­è°ƒç”¨åŸå§‹çš„ onChunkï¼ˆä¼ é€’streamHandlerç´¯ç§¯çš„å®Œæ•´å†…å®¹ï¼‰
      if (onChunk) {
        onChunk({
          type: 'chunk',
          content: chunk.content,
          reasoning_content: chunk.reasoning_content,
          tool_calls: chunk.tool_calls,
          phase: chunk.phase
        });
      }
    });
    
    // æ·»åŠ è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹è¿”å›ç»“æœ
    console.log('[streamLLMChat] ğŸ” æµå®Œæˆï¼Œresult ç»“æ„:', {
      hasToolCalls: !!(result.tool_calls && result.tool_calls.length > 0),
      toolCallsLength: result.tool_calls?.length || 0,
      hasOnToolCall: !!onToolCall,
      content: result.content,
      reasoning_content: result.reasoning_content
    });
    
    if (result.tool_calls && result.tool_calls.length > 0) {
      console.log('[streamLLMChat] ğŸ” è¯¦ç»†çš„ tool_calls ç»“æ„:', JSON.stringify(result.tool_calls, null, 2));
    }
    
    // æµå¤„ç†å®Œæˆåï¼Œæ£€æŸ¥æœ€ç»ˆèšåˆçš„å·¥å…·è°ƒç”¨
    if (result.tool_calls && result.tool_calls.length > 0 && onToolCall) {
      console.log('[streamLLMChat] ğŸ” æµå®Œæˆï¼Œæ£€æŸ¥æœ€ç»ˆå·¥å…·è°ƒç”¨:', result.tool_calls.length, 'ä¸ª');
      
      for (const toolCall of result.tool_calls) {
        if (toolCall.function && toolCall.function.name && toolCall.function.arguments !== undefined) {
          const toolKey = `${toolCall.id || toolCall.function.name}`;
          
          console.log('[streamLLMChat] æ£€æŸ¥æœ€ç»ˆå·¥å…·è°ƒç”¨:', toolCall.function.name, 'ID:', toolCall.id, 'arguments:', JSON.stringify(toolCall.function.arguments));
          
          // åªè§¦å‘æœªè§¦å‘è¿‡çš„å·¥å…·è°ƒç”¨
          if (!triggeredToolCalls.has(toolKey)) {
            try {
              // éªŒè¯ arguments æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå…è®¸ç©ºå­—ç¬¦ä¸²
              let parsedArgs = {};
              const argsStr = toolCall.function.arguments?.trim();
              if (argsStr && argsStr !== '') {
                parsedArgs = JSON.parse(argsStr);
              }
              console.log('[streamLLMChat] âœ… æµå®Œæˆåæ£€æµ‹åˆ°å®Œæ•´å·¥å…·è°ƒç”¨:', toolCall.function.name, 'ID:', toolCall.id, 'è§£æçš„å‚æ•°:', parsedArgs);
              triggeredToolCalls.add(toolKey);
              onToolCall(toolCall);
            } catch (e) {
              console.log('[streamLLMChat] âŒ æµå®Œæˆåå·¥å…·è°ƒç”¨å‚æ•°è§£æå¤±è´¥:', toolCall.function.name, 'arguments:', JSON.stringify(toolCall.function.arguments), 'error:', e);
              // å³ä½¿è§£æå¤±è´¥ï¼Œä¹Ÿå°è¯•è§¦å‘å·¥å…·è°ƒç”¨ï¼ˆä½¿ç”¨ç©ºå‚æ•°ï¼‰
              console.log('[streamLLMChat] ğŸ”„ å°è¯•ä½¿ç”¨ç©ºå‚æ•°è§¦å‘å·¥å…·è°ƒç”¨');
              triggeredToolCalls.add(toolKey);
              onToolCall(toolCall);
            }
          } else {
            console.log('[streamLLMChat] âš ï¸  æœ€ç»ˆå·¥å…·è°ƒç”¨å·²è§¦å‘è¿‡ï¼Œè·³è¿‡:', toolCall.function.name);
          }
        } else {
          console.log('[streamLLMChat] âŒ æœ€ç»ˆå·¥å…·è°ƒç”¨ç¼ºå°‘å¿…è¦ä¿¡æ¯ - function:', !!toolCall.function, 'name:', toolCall.function?.name, 'arguments:', !!toolCall.function?.arguments);
        }
      }
    } else {
      console.log('[streamLLMChat] ğŸ“ æµå®Œæˆï¼Œæ— å·¥å…·è°ƒç”¨æˆ–å›è°ƒæœªæä¾›');
    }
    
    // æµå¤„ç†å®Œæˆåï¼Œè°ƒç”¨ onDone å›è°ƒï¼Œç¡®ä¿è¿”å›å®Œæ•´çš„ EnrichedMessage æ ¼å¼
    if (onDone) {
      const enrichedResult = {
        role: 'assistant' as const,
        content: result.content,
        id: assistantMessageId, // ä½¿ç”¨ä¼ å…¥çš„ IDï¼Œé¿å…é‡æ–°ç”Ÿæˆ
        // åªåœ¨æµå®Œæˆæ—¶è®¾ç½®æœ€ç»ˆçš„ timestampï¼Œé¿å…é¢‘ç¹æ›´æ–°
        timestamp: Date.now(),
        ...(result.reasoning_content && { reasoning_content: result.reasoning_content }),
        ...(result.tool_calls && result.tool_calls.length > 0 && { tool_calls: result.tool_calls }),
      };
      onDone(enrichedResult);
    }
  } catch (err) {
    if (onError) onError(err);
  }
}

export function abortLLMStream() {
  currentStream = null;
}

// å¹³å°é€‚é…å¯¹è±¡ï¼šwebä¸‹ç›´æ¥è°ƒç”¨streamLLMChatï¼Œç»Ÿä¸€äº‹ä»¶åˆ†å‘
export const llmService = {
  /**
   * ç»Ÿä¸€åè®®æ¶ˆæ¯å‘é€ï¼Œwebä¸‹ç›´æ¥è°ƒç”¨ streamLLMChat
   * @param type æ¶ˆæ¯ç±»å‹ï¼ˆä»…æ”¯æŒ message/llm/chatï¼‰
   * @param payload LLMè¯·æ±‚å‚æ•°
   * @param callback ç»Ÿä¸€äº‹ä»¶å›è°ƒ { type, ... }
   */
  send(type: string, payload: any, callback: (msg: any) => void) {
    if (type !== 'message/llm/chat') {
      console.warn('llmService.send: ä»…æ”¯æŒ message/llm/chat');
      return;
    }
    streamLLMChat({
      ...payload,
      onChunk: (data: any) => callback({ type: 'chunk', ...data }),
      onDone: (data: any) => callback({ type: 'done', ...data }),
      onError: (err: any) => callback({ type: 'error', ...err }),
      onAbort: (info: any) => callback({ type: 'abort', ...info }),
      onToolCall: (toolCall: any) => callback({ type: 'toolcall', ...toolCall }),
    });
  },

  /**
   * ä¸­æ–­ LLM æ¨ç†ï¼ˆå¯é€‰å®ç°ï¼‰
   */
  abort(type: string, payload: any, callback: (msg: any) => void) {
    // å¦‚æœ‰ abort èƒ½åŠ›å¯å®ç°ï¼Œå¦åˆ™ç•™ç©º
    // abortLLMStream();
    callback({ type: 'abort', ...payload });
  }
};

// ç”¨æ³•ç¤ºä¾‹ï¼š
// llmService.send('message/llm/chat', payload, (msg) => { ... })
// llmService.abort('message/llm/abort', payload, (msg) => { ... })
